---
title: "How to Configure OpenRouter with Continue"
sidebarTitle: "OpenRouter"
description: "Configure OpenRouter with Continue to access various commercial and open-source models through a unified interface, including model capability configuration and advanced request options"
---

OpenRouter is a unified interface for commercial and open-source models, giving you access to the best models at the best prices. You can sign up [here](https://openrouter.ai/signup), create your API key on the [keys page](https://openrouter.ai/keys), and then choose a model from the [list of supported models](https://openrouter.ai/models).

Change `~/.continue/config.yaml` to look like the following.

<Tabs>
  <Tab title="YAML">
  ```yaml title="config.yaml"
  models:
    - name: OpenRouter LLaMA 70 8B
      provider: openrouter
      model: meta-llama/llama-3-70b-instruct
      apiBase: https://openrouter.ai/api/v1
      apiKey: <YOUR_OPEN_ROUTER_API_KEY>
  ```
  </Tab>
  <Tab title="JSON">
  ```json title="config.json"
  {
    "models": [
      {
        "title": "OpenRouter LLaMA 70 8B",
        "provider": "openrouter",
        "model": "meta-llama/llama-3-70b-instruct",
        "apiBase": "https://openrouter.ai/api/v1",
        "apiKey": "<YOUR_OPEN_ROUTER_API_KEY>"
      }
    ]
  }
  ```
  </Tab>
</Tabs>

## Using Custom Models

To use a model that is not in the dropdown list, you can simply enter the model name in the `model` field. For example, to use Qwen3Coder, you would update your configuration to look like this:

<Tabs>
  <Tab title="YAML">
  ```yaml title="config.yaml"
  models:
    - name: Qwen3Coder
      provider: openrouter
      model: qwen/qwen-coder
      apiBase: https://openrouter.ai/api/v1
      apiKey: <YOUR_OPEN_ROUTER_API_KEY>
  ```
  </Tab>
  <Tab title="JSON">
  ```json title="config.json"
  {
    "models": [
      {
        "title": "Qwen3Coder",
        "provider": "openrouter",
        "model": "qwen/qwen-coder",
        "apiBase": "https://openrouter.ai/api/v1",
        "apiKey": "<YOUR_OPEN_ROUTER_API_KEY>"
      }
    ]
  }
  ```
  </Tab>
</Tabs>

To utilize features such as provider preferences or model routing configuration, include these parameters inside the `models[].requestsOptions.extraBodyProperties` field of your plugin config.

For example, to route requests to a specific provider, you can use the `provider` field like so:

<Tabs>
  <Tab title="YAML">
  ```yaml title="config.yaml"
  models:
    - name: Example Model
      provider: exampleProvider
      model: example-model
      requestOptions:
        extraBodyProperties:
          provider: "anthropic"
  ```
  </Tab>
  <Tab title="JSON">
  ```json title="config.json"
  {
    "models": [
      {
        "title": "Example Model",
        "provider": "exampleProvider",
        "model": "example-model",
        "requestOptions": {
          "extraBodyProperties": {
            "provider": "anthropic"
          }
        }
      }
    ]
  }
  ```
  </Tab>
</Tabs>

Learn more about available settings [here](https://openrouter.ai/docs).

## Model Capabilities

Continue automatically determines whether a model supports native tool calling. You can see the full list of supported models [here](https://github.com/continuedev/continue/blob/main/core/src/llm/toolSupport.ts).

If you're experiencing issues with Agent mode or tools not working, you can add the `capabilities` field to override the default behavior:

<Tabs>
  <Tab title="YAML">
  ```yaml title="config.yaml"
  models:
    - name: Claude via OpenRouter
      provider: openrouter
      model: anthropic/claude-3.5-sonnet
      apiBase: https://openrouter.ai/api/v1
      apiKey: <YOUR_OPEN_ROUTER_API_KEY>
      capabilities:
        tools: true      # Enable function calling for Agent mode
        image_input: true   # Enable image upload support
  ```
  </Tab>
  <Tab title="JSON">
  ```json title="config.json"
  {
    "models": [
      {
        "title": "Claude via OpenRouter",
        "provider": "openrouter",
        "model": "anthropic/claude-3.5-sonnet",
        "apiBase": "https://openrouter.ai/api/v1",
        "apiKey": "<YOUR_OPEN_ROUTER_API_KEY>",
        "capabilities": {
          "tools": true,
          "uploadImage": true
        }
      }
    ]
  }
  ```
  </Tab>
</Tabs>

Note: Not all models support function calling. Check the [OpenRouter models page](https://openrouter.ai/models) for specific model capabilities.

## System Message Tools

For models that do not support native tool calling, Continue will automatically use "system message tools". This means that the tool definitions and calls are embedded in the system message as text. This allows you to use tools with models that don't natively support them.

This feature is enabled by default for all OpenRouter models except for Claude models, which have good native tool calling support.

